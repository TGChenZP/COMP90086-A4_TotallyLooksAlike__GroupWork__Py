{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90086 Asmt 4 Model Main Control IPYNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# py_file_location = \"./drive/My Drive/LAB/COMP90086\"\n",
    "# sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries and network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from environment import *\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ROOT = './drive/My Drive/LAB/COMP90086/COMP90086_2023_TLLdataset 2'\n",
    "ROOT = './COMP90086_2023_TLLdataset 2'\n",
    "seed = 19260817 # set seed\n",
    "IMAGE_SIZE = 0\n",
    "data_list = pd.read_csv(ROOT + '/train.csv')\n",
    "future_list = pd.read_csv(ROOT + '/test_candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1362.99it/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1358.04it/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1355.93it/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1374.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# preload all images\n",
    "\n",
    "imgs = dict()\n",
    "for img in tqdm(os.listdir(ROOT+'/train/left')):\n",
    "    imgs[img] = prepare_image(ROOT+'/train/left/'+img, resize_shape=IMAGE_SIZE)\n",
    "\n",
    "for img in tqdm(os.listdir(ROOT+'/train/right')):\n",
    "    imgs[img] = prepare_image(ROOT+'/train/right/'+img, resize_shape=IMAGE_SIZE)\n",
    "\n",
    "for img in tqdm(os.listdir(ROOT+'/test/left')):\n",
    "    imgs[img] = prepare_image(ROOT+'/test/left/'+img, resize_shape=IMAGE_SIZE)\n",
    "\n",
    "for img in tqdm(os.listdir(ROOT+'/test/right')):\n",
    "    imgs[img] = prepare_image(ROOT+'/test/right/'+img, resize_shape=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Val Test Split\n",
    "train_list, valtest_list = train_test_split(data_list, test_size=0.3, random_state=seed) # train is 70%\n",
    "val_list, test_list = train_test_split(valtest_list, test_size=0.5, random_state=seed) # val is 15%, test is 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have run Siamese Contrastive model with 4 different negative mining strategies and the result is shown below. The best result is achieved by using the semi-hard negative mining strategy (Experiment 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 1: No resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1576/1576 [04:35<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 - Loss: 0.167\n",
      "Nominal Correct: 0.58\n",
      "Validation Loss: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:33<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2 - Loss: 0.023\n",
      "Nominal Correct: 0.5866666666666667\n",
      "Validation Loss: 0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:32<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3 - Loss: 0.017\n",
      "Nominal Correct: 0.59\n",
      "Validation Loss: 0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:35<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4 - Loss: 0.017\n",
      "Nominal Correct: 0.6366666666666667\n",
      "Validation Loss: 0.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:33<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5 - Loss: 0.007\n",
      "Nominal Correct: 0.6466666666666666\n",
      "Validation Loss: 0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:35<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6 - Loss: 0.004\n",
      "Nominal Correct: 0.6433333333333333\n",
      "Validation Loss: 0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:33<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7 - Loss: 0.004\n",
      "Nominal Correct: 0.6566666666666666\n",
      "Validation Loss: 0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:34<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8 - Loss: 0.002\n",
      "Nominal Correct: 0.64\n",
      "Validation Loss: 0.470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:34<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9 - Loss: 0.002\n",
      "Nominal Correct: 0.6366666666666667\n",
      "Validation Loss: 0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:34<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 - Loss: 0.001\n",
      "Nominal Correct: 0.63\n",
      "Validation Loss: 0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:36<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 - Loss: 0.001\n",
      "Nominal Correct: 0.62\n",
      "Validation Loss: 0.455\n",
      "Best Validation:\n",
      "Nominal Correct: 0.6566666666666666\n",
      "Validation Loss: 0.458\n",
      "Best Test:\n",
      "Nominal Correct: 0.5533333333333333\n",
      "Nominal Correct: 0.097\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: No Resampling\n",
    "\n",
    "NAME = 'densenet201' # name of the CNN encoder on PyTorch\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Siamise_Triplet_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME \n",
    "    freeze_encoder          = False # whether to freeze the pre-trained encoder weights\n",
    "    input_shape             = (1, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (1, 3, 245, 200) # input image shape\n",
    "    num_mlp_layers          = 2 # number of layers in MLP\n",
    "    hidden_dim              = 512 # size of the hidden layer in MLP\n",
    "    dropout                 = 0.1 # dropout rate for MLP\n",
    "    res_learning            = False # whether to learn residual\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True # whether to use pre-trained weights\n",
    "    crop_pretrained_linear  = True # whether to crop linear layer from imported CNN encoder\n",
    "    final_relu              = False # whether to add ReLU to the embedding\n",
    "    # ------------------------ #\n",
    "    random_state            = seed \n",
    "    lr                      = 1e-5 # learning rate\n",
    "    loss                    = nn.TripletMarginLoss(margin = 1) # loss function\n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet # datafactory\n",
    "    DataLoader_Triplet      = DataLoader_Triplet # dataloader\n",
    "    images                  = imgs # loaded images\n",
    "    name                    = NAME + '_siamese_triplet_Expr1' # name for saving model\n",
    "    real_eval_batch_size    = 16 # real evaluation batch size\n",
    "    resample                = False # whether to do non-random negative resampling\n",
    "    num_random_sample_false = 0 # number of random negative to incorporate under non-random  negative sampling scheme\n",
    "    semi_hard               = True # if using non-random negative resampling, whether to use semi-hard negative\n",
    "    \n",
    "\n",
    "cnn_siamise_triplet = CNN_Siamise_Triplet(CNN_Siamise_Triplet_CFG)\n",
    "cnn_siamise_triplet.fit(train_list, val_list, batch_size = 16, epochs=100, patience=5, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_siamise_triplet.load()\n",
    "print('Best Validation:')\n",
    "cnn_siamise_triplet.eval(val_list, batch_size=16, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_siamise_triplet.real_eval(future_test_list, 1)\n",
    "\n",
    "final_out1, score = cnn_siamise_triplet.real_eval(future_list, 1)\n",
    "final_out1.to_csv(f'./{NAME}_siamese_triplet_Expr1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 2: Semi-hard negative mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1576/1576 [04:34<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 - Loss: 0.167\n",
      "Nominal Correct: 0.56\n",
      "Validation Loss: 0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:43<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2 - Loss: 0.129\n",
      "Nominal Correct: 0.5433333333333333\n",
      "Validation Loss: 0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:42<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3 - Loss: 0.049\n",
      "Nominal Correct: 0.6533333333333333\n",
      "Validation Loss: 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:43<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4 - Loss: 0.031\n",
      "Nominal Correct: 0.61\n",
      "Validation Loss: 0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:43<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5 - Loss: 0.021\n",
      "Nominal Correct: 0.6466666666666666\n",
      "Validation Loss: 0.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:43<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6 - Loss: 0.020\n",
      "Nominal Correct: 0.6466666666666666\n",
      "Validation Loss: 0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:44<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7 - Loss: 0.003\n",
      "Nominal Correct: 0.6566666666666666\n",
      "Validation Loss: 0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:42<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8 - Loss: 0.004\n",
      "Nominal Correct: 0.6733333333333333\n",
      "Validation Loss: 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:42<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9 - Loss: 0.003\n",
      "Nominal Correct: 0.68\n",
      "Validation Loss: 0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:41<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 - Loss: 0.001\n",
      "Nominal Correct: 0.6933333333333334\n",
      "Validation Loss: 0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:41<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 - Loss: 0.001\n",
      "Nominal Correct: 0.6933333333333334\n",
      "Validation Loss: 0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:40<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 - Loss: 0.002\n",
      "Nominal Correct: 0.6633333333333333\n",
      "Validation Loss: 0.411\n",
      "Best Validation:\n",
      "Nominal Correct: 0.6933333333333334\n",
      "Validation Loss: 0.402\n",
      "Best Test:\n",
      "Nominal Correct: 0.6166666666666667\n",
      "Nominal Correct: 0.096\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Semihard Resampling\n",
    "\n",
    "NAME = 'densenet201'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Siamise_Triplet_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (1, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (1, 3, 245, 200)\n",
    "    num_mlp_layers          = 2\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True      \n",
    "    crop_pretrained_linear  = True\n",
    "    final_relu              = False\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.TripletMarginLoss(margin = 1) \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "    name                    = NAME + '_siamese_triplet_Expr2'\n",
    "    real_eval_batch_size    = 16\n",
    "    resample                = True\n",
    "    num_random_sample_false = 0\n",
    "    semi_hard               = True\n",
    "    \n",
    "\n",
    "cnn_siamise_triplet = CNN_Siamise_Triplet(CNN_Siamise_Triplet_CFG)\n",
    "cnn_siamise_triplet.fit(train_list, val_list, batch_size = 16, epochs=100, patience=5, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_siamise_triplet.load()\n",
    "print('Best Validation:')\n",
    "cnn_siamise_triplet.eval(val_list, batch_size=16, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_siamise_triplet.real_eval(future_test_list, 1)\n",
    "\n",
    "final_out1, score = cnn_siamise_triplet.real_eval(future_list, 1)\n",
    "final_out1.to_csv(f'./{NAME}_siamese_triplet_Expr2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 3: Hard negative mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1576/1576 [04:38<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 - Loss: 0.167\n",
      "Nominal Correct: 0.56\n",
      "Validation Loss: 0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:45<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2 - Loss: 0.222\n",
      "Nominal Correct: 0.5666666666666667\n",
      "Validation Loss: 0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:47<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3 - Loss: 0.151\n",
      "Nominal Correct: 0.6\n",
      "Validation Loss: 0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:44<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4 - Loss: 0.140\n",
      "Nominal Correct: 0.5766666666666667\n",
      "Validation Loss: 0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:49<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5 - Loss: 0.133\n",
      "Nominal Correct: 0.6166666666666667\n",
      "Validation Loss: 0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:46<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6 - Loss: 0.130\n",
      "Nominal Correct: 0.6433333333333333\n",
      "Validation Loss: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:50<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7 - Loss: 0.115\n",
      "Nominal Correct: 0.6766666666666666\n",
      "Validation Loss: 0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:49<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8 - Loss: 0.114\n",
      "Nominal Correct: 0.65\n",
      "Validation Loss: 0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:45<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9 - Loss: 0.114\n",
      "Nominal Correct: 0.64\n",
      "Validation Loss: 0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:45<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 - Loss: 0.114\n",
      "Nominal Correct: 0.6266666666666667\n",
      "Validation Loss: 0.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:46<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 - Loss: 0.114\n",
      "Nominal Correct: 0.6833333333333333\n",
      "Validation Loss: 0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:46<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 - Loss: 0.112\n",
      "Nominal Correct: 0.68\n",
      "Validation Loss: 0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:46<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13 - Loss: 0.111\n",
      "Nominal Correct: 0.6933333333333334\n",
      "Validation Loss: 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:45<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 - Loss: 0.112\n",
      "Nominal Correct: 0.6533333333333333\n",
      "Validation Loss: 0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:43<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 - Loss: 0.112\n",
      "Nominal Correct: 0.66\n",
      "Validation Loss: 0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:46<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 - Loss: 0.112\n",
      "Nominal Correct: 0.6666666666666666\n",
      "Validation Loss: 0.479\n",
      "Best Validation:\n",
      "Nominal Correct: 0.6933333333333334\n",
      "Validation Loss: 0.445\n",
      "Best Test:\n",
      "Nominal Correct: 0.5933333333333334\n",
      "Nominal Correct: 0.097\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Hard Resampling\n",
    "NAME = 'densenet201'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Siamise_Triplet_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (1, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (1, 3, 245, 200)\n",
    "    num_mlp_layers          = 2\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True      \n",
    "    crop_pretrained_linear  = True\n",
    "    final_relu              = False\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.TripletMarginLoss(margin = 1) \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "    name                    = NAME + '_siamese_triplet_Expr3'\n",
    "    real_eval_batch_size    = 16\n",
    "    resample                = True\n",
    "    num_random_sample_false = 0\n",
    "    semi_hard               = False\n",
    "    \n",
    "\n",
    "cnn_siamise_triplet = CNN_Siamise_Triplet(CNN_Siamise_Triplet_CFG)\n",
    "cnn_siamise_triplet.fit(train_list, val_list, batch_size = 16, epochs=100, patience=8, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_siamise_triplet.load()\n",
    "print('Best Validation:')\n",
    "cnn_siamise_triplet.eval(val_list, batch_size=16, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_siamise_triplet.real_eval(future_test_list, 1)\n",
    "\n",
    "final_out1, score = cnn_siamise_triplet.real_eval(future_list, 1)\n",
    "final_out1.to_csv(f'./{NAME}_siamese_triplet_Expr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 4: Semi-hard negative mining with random negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1576/1576 [04:55<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 - Loss: 0.168\n",
      "Nominal Correct: 0.5866666666666667\n",
      "Validation Loss: 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:50<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2 - Loss: 0.117\n",
      "Nominal Correct: 0.5933333333333334\n",
      "Validation Loss: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:55<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3 - Loss: 0.048\n",
      "Nominal Correct: 0.6133333333333333\n",
      "Validation Loss: 0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:54<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4 - Loss: 0.029\n",
      "Nominal Correct: 0.6233333333333333\n",
      "Validation Loss: 0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:53<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5 - Loss: 0.025\n",
      "Nominal Correct: 0.6233333333333333\n",
      "Validation Loss: 0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6 - Loss: 0.022\n",
      "Nominal Correct: 0.63\n",
      "Validation Loss: 0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:54<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7 - Loss: 0.019\n",
      "Nominal Correct: 0.63\n",
      "Validation Loss: 0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:52<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8 - Loss: 0.016\n",
      "Nominal Correct: 0.6533333333333333\n",
      "Validation Loss: 0.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:55<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9 - Loss: 0.003\n",
      "Nominal Correct: 0.68\n",
      "Validation Loss: 0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:53<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 - Loss: 0.004\n",
      "Nominal Correct: 0.6666666666666666\n",
      "Validation Loss: 0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:55<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 - Loss: 0.003\n",
      "Nominal Correct: 0.6533333333333333\n",
      "Validation Loss: 0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:52<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 - Loss: 0.003\n",
      "Nominal Correct: 0.6966666666666667\n",
      "Validation Loss: 0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13 - Loss: 0.003\n",
      "Nominal Correct: 0.6833333333333333\n",
      "Validation Loss: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:54<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 - Loss: 0.001\n",
      "Nominal Correct: 0.6966666666666667\n",
      "Validation Loss: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:50<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 - Loss: 0.001\n",
      "Nominal Correct: 0.67\n",
      "Validation Loss: 0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:53<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 - Loss: 0.001\n",
      "Nominal Correct: 0.6766666666666666\n",
      "Validation Loss: 0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:54<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17 - Loss: 0.001\n",
      "Nominal Correct: 0.68\n",
      "Validation Loss: 0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:52<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18 - Loss: 0.001\n",
      "Nominal Correct: 0.6866666666666666\n",
      "Validation Loss: 0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:49<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19 - Loss: 0.000\n",
      "Nominal Correct: 0.71\n",
      "Validation Loss: 0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:53<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 - Loss: 0.000\n",
      "Nominal Correct: 0.6933333333333334\n",
      "Validation Loss: 0.418\n",
      "Best Validation:\n",
      "Nominal Correct: 0.71\n",
      "Validation Loss: 0.417\n",
      "Best Test:\n",
      "Nominal Correct: 0.5533333333333333\n",
      "Nominal Correct: 0.0885\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: Semihard Resampling + Random\n",
    "NAME = 'densenet201'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Siamise_Triplet_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (1, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (1, 3, 245, 200)\n",
    "    num_mlp_layers          = 2\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True      \n",
    "    crop_pretrained_linear  = True\n",
    "    final_relu              = False\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.TripletMarginLoss(margin = 1) \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "    name                    = NAME + '_siamese_triplet_Expr4'\n",
    "    real_eval_batch_size    = 16\n",
    "    resample                = True\n",
    "    num_random_sample_false = 4\n",
    "    semi_hard               = True\n",
    "    \n",
    "\n",
    "cnn_siamise_triplet = CNN_Siamise_Triplet(CNN_Siamise_Triplet_CFG)\n",
    "cnn_siamise_triplet.fit(train_list, val_list, batch_size = 16, epochs=100, patience=8, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_siamise_triplet.load()\n",
    "print('Best Validation:')\n",
    "cnn_siamise_triplet.eval(val_list, batch_size=16, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_siamise_triplet.real_eval(future_test_list, 1)\n",
    "\n",
    "final_out1, score = cnn_siamise_triplet.real_eval(future_list, 1)\n",
    "final_out1.to_csv(f'./{NAME}_siamese_triplet_Expr4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1576/1576 [05:00<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 - Loss: 0.270\n",
      "Nominal Correct: 0.5933333333333334\n",
      "Validation Loss: 1.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2 - Loss: 0.135\n",
      "Nominal Correct: 0.5866666666666667\n",
      "Validation Loss: 1.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3 - Loss: 0.071\n",
      "Nominal Correct: 0.57\n",
      "Validation Loss: 1.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:50<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4 - Loss: 0.050\n",
      "Nominal Correct: 0.6133333333333333\n",
      "Validation Loss: 1.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5 - Loss: 0.044\n",
      "Nominal Correct: 0.6\n",
      "Validation Loss: 1.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6 - Loss: 0.036\n",
      "Nominal Correct: 0.64\n",
      "Validation Loss: 1.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:50<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7 - Loss: 0.032\n",
      "Nominal Correct: 0.63\n",
      "Validation Loss: 1.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:47<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8 - Loss: 0.033\n",
      "Nominal Correct: 0.6433333333333333\n",
      "Validation Loss: 1.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:53<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9 - Loss: 0.027\n",
      "Nominal Correct: 0.59\n",
      "Validation Loss: 1.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:51<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 - Loss: 0.023\n",
      "Nominal Correct: 0.64\n",
      "Validation Loss: 1.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:53<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 - Loss: 0.027\n",
      "Nominal Correct: 0.6266666666666667\n",
      "Validation Loss: 1.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1576/1576 [04:49<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12 - Loss: 0.004\n",
      "Nominal Correct: 0.62\n",
      "Validation Loss: 1.327\n",
      "Best Validation:\n",
      "Nominal Correct: 0.6433333333333333\n",
      "Validation Loss: 1.118\n",
      "Best Test:\n",
      "Nominal Correct: 0.5733333333333334\n",
      "Nominal Correct: 0.094\n"
     ]
    }
   ],
   "source": [
    "# Experiment 5: Double Triplet Loss\n",
    "NAME = 'densenet201'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Siamise_Triplet_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (1, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (1, 3, 245, 200)\n",
    "    num_mlp_layers          = 2\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True      \n",
    "    crop_pretrained_linear  = True\n",
    "    final_relu              = False\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = Double_Triplet_Loss(margin=1.0, margin_p = 0.5)\n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "    name                    = NAME + '_siamese_triplet_Expr5'\n",
    "    real_eval_batch_size    = 16\n",
    "    resample                = True\n",
    "    num_random_sample_false = 0\n",
    "    semi_hard               = True\n",
    "    \n",
    "\n",
    "cnn_siamise_triplet = CNN_Siamise_Triplet(CNN_Siamise_Triplet_CFG)\n",
    "cnn_siamise_triplet.fit(train_list, val_list, batch_size = 16, epochs=100, patience=8, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_siamise_triplet.load()\n",
    "print('Best Validation:')\n",
    "cnn_siamise_triplet.eval(val_list, batch_size=16, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_siamise_triplet.real_eval(future_test_list, 1)\n",
    "\n",
    "final_out1, score = cnn_siamise_triplet.real_eval(future_list, 1)\n",
    "final_out1.to_csv(f'./{NAME}_siamese_triplet_Expr5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Query Contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'densenet201'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "class CNN_Key_Query_Triplet_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (64, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (64, 3, 245, 200)\n",
    "    num_mlp_layers          = 2\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True      \n",
    "    crop_pretrained_linear  = True\n",
    "    final_relu              = False\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.TripletMarginLoss() \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "    name                    = NAME + 'key_query'\n",
    "    real_eval_batch_size    = 16\n",
    "    resample                = True\n",
    "    num_random_sample_false = 0\n",
    "    semi_hard               = True\n",
    "    \n",
    "\n",
    "cnn_key_query_triplet = CNN_Key_Query_Triplet(CNN_Key_Query_Triplet_CFG)\n",
    "cnn_key_query_triplet.fit(train_list, val_list, batch_size = 16, epochs=100, patience=5, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_key_query_triplet.load()\n",
    "print('Best Validation:')\n",
    "cnn_key_query_triplet.eval(val_list, batch_size=16, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_key_query_triplet.real_eval(future_test_list, 2)\n",
    "\n",
    "final_out1, score = cnn_key_query_triplet.real_eval(future_list, 2)\n",
    "final_out1.to_csv(f'./{NAME}_key_query_triplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Record\n",
    "\n",
    "# 100%|██████████| 1576/1576 [05:01<00:00,  5.23it/s]\n",
    "# Epoch:   1 - Loss: 0.308\n",
    "# Nominal Correct: 0.5233333333333333\n",
    "# Validation Loss: 0.396\n",
    "# 100%|██████████| 1576/1576 [05:05<00:00,  5.16it/s]\n",
    "# Epoch:   2 - Loss: 0.366\n",
    "# Nominal Correct: 0.44\n",
    "# Validation Loss: 0.538\n",
    "# 100%|██████████| 1576/1576 [05:02<00:00,  5.21it/s]\n",
    "# Epoch:   3 - Loss: 0.125\n",
    "# Nominal Correct: 0.55\n",
    "# Validation Loss: 0.401\n",
    "# 100%|██████████| 1576/1576 [05:02<00:00,  5.21it/s]\n",
    "# Epoch:   4 - Loss: 0.096\n",
    "# Nominal Correct: 0.49666666666666665\n",
    "# Validation Loss: 0.527\n",
    "# 100%|██████████| 1576/1576 [05:07<00:00,  5.12it/s]\n",
    "# Epoch:   5 - Loss: 0.031\n",
    "# Nominal Correct: 0.6133333333333333\n",
    "# Validation Loss: 0.386\n",
    "# 100%|██████████| 1576/1576 [05:08<00:00,  5.11it/s]\n",
    "# Epoch:   6 - Loss: 0.029\n",
    "# Nominal Correct: 0.5666666666666667\n",
    "# Validation Loss: 0.438\n",
    "# 100%|██████████| 1576/1576 [05:11<00:00,  5.05it/s]\n",
    "# Epoch:   7 - Loss: 0.016\n",
    "# Nominal Correct: 0.5966666666666667\n",
    "# Validation Loss: 0.406\n",
    "# 100%|██████████| 1576/1576 [05:08<00:00,  5.12it/s]\n",
    "# Epoch:   8 - Loss: 0.015\n",
    "# Nominal Correct: 0.6166666666666667\n",
    "# Validation Loss: 0.394\n",
    "# 100%|██████████| 1576/1576 [05:09<00:00,  5.10it/s]\n",
    "# Epoch:   9 - Loss: 0.004\n",
    "# Nominal Correct: 0.64\n",
    "# Validation Loss: 0.391\n",
    "# 100%|██████████| 1576/1576 [05:05<00:00,  5.17it/s]\n",
    "# Epoch:  10 - Loss: 0.003\n",
    "# Nominal Correct: 0.6533333333333333\n",
    "# Validation Loss: 0.393\n",
    "# 100%|██████████| 1576/1576 [05:06<00:00,  5.14it/s]\n",
    "# Epoch:  11 - Loss: 0.004\n",
    "# Nominal Correct: 0.5866666666666667\n",
    "# Validation Loss: 0.429\n",
    "\n",
    "# Best Validation:\n",
    "# Nominal Correct: 0.6533333333333333\n",
    "# Validation Loss: 0.393\n",
    "# Best Test:\n",
    "# Nominal Correct: 0.57\n",
    "# Nominal Correct: 0.0925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamise Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'densenet121'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Siamise_Categorisation_CFG:\n",
    "    num_false               = 9 # how many hard negative to try for each anchor\n",
    "    encoder                 = NAME\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (1, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (1, 3, 245, 200)\n",
    "    num_mlp_layers          = 2\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 128 # size of the actual embedding for each image\n",
    "    pretrained              = True      \n",
    "    crop_pretrained_linear  = True\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.BCELoss() \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "    name                    = NAME +'siamese_categorisation'\n",
    "    real_eval_batch_size    = 10\n",
    "\n",
    "cnn_siamise_categorisation = CNN_Siamise_Categorisation(CNN_Siamise_Categorisation_CFG)\n",
    "cnn_siamise_categorisation.fit(train_list, val_list, batch_size = 32, epochs=100, patience=8, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_siamise_categorisation.load()\n",
    "print('Best Validation:')\n",
    "cnn_siamise_categorisation.eval(val_list, batch_size=32, return_loss=False)\n",
    "\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_siamise_categorisation.real_eval(future_test_list, 10)\n",
    "\n",
    "final_out2 = cnn_siamise_categorisation.real_eval(future_list, 10)\n",
    "final_out2.to_csv(f'./{NAME}_siamese_categorisation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Query Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'resnet'\n",
    "\n",
    "for _ in range(2):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "class CNN_Key_Query_Categorisation_CFG:\n",
    "    num_false               = 1 # how many false samples for each true sample\n",
    "    target                  = 1 # target loss for correct. false will be 1-target\n",
    "    encoder                 = NAME # the name of the model we want to load from torchhub\n",
    "    freeze_encoder          = True\n",
    "    input_shape             = (64, 3, IMAGE_SIZE, IMAGE_SIZE) if IMAGE_SIZE else (64, 3, 245, 200)  # (batch size, 3, [what our loaded in images look like])\n",
    "    num_mlp_layers          = 2 # how many mlp layers in the end. 0 means no mlp and just 1 out layer; n means n mlp + outlayer\n",
    "    hidden_dim              = 512 # hidden dim of mlp\n",
    "    dropout                 = 0.1 # dropout rate of mlp\n",
    "    res_learning            = False # whether to use residual layer in mlp\n",
    "    pretrained              = True # whether to use pretrained encoder\n",
    "    crop_pretrained_linear  = True\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.BCELoss()   \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpatbbh for saving models\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Categorisation = DataFactory_Categorisation\n",
    "    DataLoader_Categorisation = DataLoader_Categorisation\n",
    "    images                  = imgs\n",
    "    name                    = NAME + '_categorisation'\n",
    "    real_eval_batch_size    = 64\n",
    "    resample                = True\n",
    "    num_random_sample       = 9\n",
    "\n",
    "\n",
    "cnn_key_query_categorisation = CNN_Key_Query_Categorisation(CNN_Key_Query_Categorisation_CFG)\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_key_query_categorisation.real_eval(future_test_list, 21)\n",
    "cnn_key_query_categorisation.fit(train_list, val_list, batch_size = 64, epochs=100, patience=8, scheduler=True, grad_clip=False, mark='')\n",
    "\n",
    "cnn_key_query_categorisation.load()\n",
    "print('Best Validation:')\n",
    "cnn_key_query_categorisation.eval(val_list, batch_size=128, return_loss=False)\n",
    "\n",
    "print('Best Test:')\n",
    "future_test_list = turn_val_into_future(test_list, seed)\n",
    "cnn_key_query_categorisation.real_eval(future_test_list, 100)\n",
    "\n",
    "final_out2 = cnn_key_query_categorisation.real_eval(future_list, 100)\n",
    "final_out2.to_csv(f'./{NAME}_key_query_categorisation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
