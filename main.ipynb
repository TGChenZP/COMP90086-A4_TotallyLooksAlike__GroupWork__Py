{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# py_file_location = \"./drive/My Drive/LAB/COMP90086\"\n",
    "# sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from environment import *\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT = './drive/My Drive/LAB/COMP90086/COMP90086_2023_TLLdataset 2'\n",
    "ROOT = './COMP90086_2023_TLLdataset 2'\n",
    "seed = 19260817\n",
    "data_list = pd.read_csv(ROOT + '/train.csv')\n",
    "future_list = pd.read_csv(ROOT + '/test_candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1139.90it/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1145.60it/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1152.42it/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1125.06it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs = dict()\n",
    "for img in tqdm(os.listdir(ROOT+'/train/left')):\n",
    "  imgs[img] = prepare_image(ROOT+'/train/left/'+img)\n",
    "\n",
    "for img in tqdm(os.listdir(ROOT+'/train/right')):\n",
    "  imgs[img] = prepare_image(ROOT+'/train/right/'+img)\n",
    "\n",
    "for img in tqdm(os.listdir(ROOT+'/test/left')):\n",
    "  imgs[img] = prepare_image(ROOT+'/test/left/'+img)\n",
    "\n",
    "for img in tqdm(os.listdir(ROOT+'/test/right')):\n",
    "  imgs[img] = prepare_image(ROOT+'/test/right/'+img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, valtest_list = train_test_split(data_list, test_size=0.3, random_state=seed) # train is 70%\n",
    "val_list, test_list = train_test_split(valtest_list, test_size=0.5, random_state=seed) # val is 15%, test is 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Key_Query_Categorisation_CFG:\n",
    "    num_false               = 1 # how many false samples for each true sample\n",
    "    target                  = 1 # target loss for correct. false will be 1-target\n",
    "    encoder                 = 'resnet18' # the name of the model we want to load from torchhub\n",
    "    freeze_encoder          = False\n",
    "    input_shape             = (64, 3, 245, 200) # (batch size, 3, [what our loaded in images look like])\n",
    "    num_mlp_layers          = 1 # how many mlp layers in the end. 0 means no mlp and just 1 out layer; n means (n+1)mlp + out\n",
    "    hidden_dim              = 512 # hidden dim of mlp\n",
    "    dropout                 = 0.1 # dropout rate of mlp\n",
    "    res_learning            = False # whether to use residual layer in mlp\n",
    "    pretrained              = True # whether to use pretrained encoder\n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.BCELoss()   \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving models\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Categorisation = DataFactory_Categorisation\n",
    "    DataLoader_Categorisation = DataLoader_Categorisation\n",
    "    images                  = imgs\n",
    "\n",
    "cnn_key_query_categorisation = CNN_Key_Query_Categorisation(CNN_Key_Query_Categorisation_CFG)\n",
    "cnn_key_query_categorisation.fit(train_list, val_list, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Key_Query_Triplet_CFG:\n",
    "    num_false               = 1 # how many hard negative to try for each anchor\n",
    "    encoder                 = 'resnet18'\n",
    "    freeze_encoder          = True\n",
    "    input_shape             = (64, 3, 245, 200)\n",
    "    num_mlp_layers          = 1\n",
    "    hidden_dim              = 512\n",
    "    dropout                 = 0.1\n",
    "    res_learning            = False\n",
    "    embed_dim               = 64\n",
    "    pretrained              = True      \n",
    "    # ------------------------ #\n",
    "    random_state            = seed\n",
    "    lr                      = 1e-5\n",
    "    loss                    = nn.TripletMarginLoss() \n",
    "    ROOT                    = ROOT # rootpath for loading images\n",
    "    rootpath                = './' # rootpath for saving\n",
    "    # rootpath                = py_file_location\n",
    "    DataFactory_Triplet     = DataFactory_Triplet\n",
    "    DataLoader_Triplet      = DataLoader_Triplet\n",
    "    images                  = imgs\n",
    "\n",
    "cnn_key_query_triplet = CNN_Key_Query_Triplet(CNN_Key_Query_Triplet_CFG)\n",
    "cnn_key_query_triplet.fit(train_list, val_list, batch_size = 64)\n",
    "\n",
    "# TODO: should we batch normalise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
